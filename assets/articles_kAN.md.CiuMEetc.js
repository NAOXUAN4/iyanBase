import{_ as a,c as t,o as e,a4 as l}from"./chunks/framework.aImdPBTI.js";const i="/iyanBase/assets/2024-05-17-19-03-14.MDwV7yLt.png",o="/iyanBase/assets/2024-05-17-20-11-11.rGB_CvTL.png",s="/iyanBase/assets/2024-05-17-20-50-51.BIo0y8Il.png",r="/iyanBase/assets/2024-05-17-21-05-46.DGH8qc_R.png",q=JSON.parse('{"title":"KAN","description":"","frontmatter":{},"headers":[],"relativePath":"articles/kAN.md","filePath":"articles/kAN.md"}'),n={name:"articles/kAN.md"},c=l('<h1 id="kan" tabindex="-1">KAN <a class="header-anchor" href="#kan" aria-label="Permalink to &quot;KAN&quot;">​</a></h1><h3 id="提出背景" tabindex="-1">提出背景 <a class="header-anchor" href="#提出背景" aria-label="Permalink to &quot;提出背景&quot;">​</a></h3><ol><li>mlp为基础的架构下,使用多级层一次线性函数,有梯度消失,梯度爆炸问题,即使后人提出dropout,L1等方法来应对上述问题,但是并不能彻底解决.</li><li>mlp为基础的网络需要大量的参数来使得网络足够智能,导致在一些任务下,模型参数量巨大.如GPT等模型有千亿以上的参数,其中核心的参数远远小于总量.</li><li>多层mlp+激活函数 来拟合非线性函数, 但是其过程中的一些线性函数也需要一次函数来拟合.何不直接使用一次函数来拟合非线性函数?</li></ol><p><img src="'+i+'" alt=""> (KAN网络的最大特征就是用样条曲线函数直接拟合线性函数)</p><ol><li>用正弦函数来拟合任意线性函数. <img src="'+o+'" alt=""></li></ol><br><ol start="2"><li>用剪枝来简化网络结构 <img src="'+s+'" alt=""></li></ol><h2 id="细节" tabindex="-1">细节 <a class="header-anchor" href="#细节" aria-label="Permalink to &quot;细节&quot;">​</a></h2><ol><li>激活函数,偏置项 <img src="'+r+'" alt=""></li></ol><h2 id="缺陷" tabindex="-1">缺陷 <a class="header-anchor" href="#缺陷" aria-label="Permalink to &quot;缺陷&quot;">​</a></h2><ol><li>计算比较复杂,gpu计算效率不高</li><li></li></ol><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2>',12),_=[c];function h(d,p,m,u,f,k){return e(),t("div",null,_)}const A=a(n,[["render",h]]);export{q as __pageData,A as default};
