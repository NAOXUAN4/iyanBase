import{_ as e,c as a,o as t,a4 as r}from"./chunks/framework.aImdPBTI.js";const n="/iyanBase/assets/2024-05-15-22-52-58.DkbvkPWQ.png",i="/iyanBase/assets/2024-05-15-23-45-20.HTEvREhN.png",s="/iyanBase/assets/2024-05-16-00-04-43.C0qDBDZ_.png",$=JSON.parse('{"title":"Vision Transformer","description":"","frontmatter":{},"headers":[],"relativePath":"articles/learning/artificial-intelligence/transformer/vit.md","filePath":"articles/learning/artificial-intelligence/transformer/vit.md"}'),o={name:"articles/learning/artificial-intelligence/transformer/vit.md"},l=r('<h1 id="vision-transformer" tabindex="-1">Vision Transformer <a class="header-anchor" href="#vision-transformer" aria-label="Permalink to &quot;Vision Transformer&quot;">​</a></h1><p><a href="https://www.bilibili.com/video/BV15P4y137jb" target="_blank" rel="noreferrer">😶‍🌫️Video</a></p><p><img src="'+n+'" alt=""></p><h2 id="解决问题" tabindex="-1">解决问题 <a class="header-anchor" href="#解决问题" aria-label="Permalink to &quot;解决问题&quot;">​</a></h2><p>1.传统trans解决nlp问题,序列长度较短,但应用于视觉领域,若用像素作为输入元素,序列长度会过长</p><h2 id="步骤" tabindex="-1">步骤 <a class="header-anchor" href="#步骤" aria-label="Permalink to &quot;步骤&quot;">​</a></h2><ol><li>将图片切成较小维度的path</li><li>用线性投射层成将图片信息变为向量 (更符合原生transformer的操作),将视觉问题适配用于解决nlp问题的transformer模型 (图片维度从 x$<em>$ y $</em>$ 3 ==&gt;&gt; patch数量个 (patchx$<em>$patchy$</em>$特征数) 的token了)</li><li>加入位置编码,分类属性(类似nlp问题中输入trans前在encoder前给文本向量添加属性的方式),把path转换为token</li><li>使用encoder模块</li><li>连接一个全连接层,将分类结果输出</li></ol><br><h2 id="q-a" tabindex="-1">Q&amp;A <a class="header-anchor" href="#q-a" aria-label="Permalink to &quot;Q&amp;A&quot;">​</a></h2><p><strong>Q1:</strong> 所有的embedding都在encoder里面做Qkv计算,在所有的输出中,把谁的输出当作模型输出结果? <strong>A1:</strong> 借鉴bert,引入<code>[cls]</code> embbding,希望&#39;[cls]&#39;能在注意力计算中能从别的embemdding学习到有用的信息,用全连接层对class embeding分类,得出模型输出.</p><br><p><strong>Q2:</strong> 位置编码是如何加入的?patch是如何变为类似nlp的token的? <strong>A2:</strong> 假设原图尺寸( 224$<em>$224$</em>$3 ),patchSize取(16 $<em>$ 16),则生成196个 (16 $</em>$ 16 $*$3) 的一维向量 ,再通过(768 * 768)的线性投影层. 输出为patch embedding <img src="'+i+'" alt=""><br></p><p><strong>Q3:</strong> 如何在patchEmbedding 里加入位置编码的? <strong>A3:</strong> 假设还是(196 * 768),直接构建一个可学习的矩阵(196 * 768) ,直接与patchEmbed相加,在初始时候初始化随机.</p><br><p><strong>Q4:</strong> [cls] token的方法是直接从nlp借鉴过来的,能用cv一般用的全局平均池化吗? <strong>A4:</strong> 在实验中,两者性能相似 <img src="'+s+'" alt=""></p>',15),c=[l];function p(m,d,h,g,_,f){return t(),a("div",null,c)}const k=e(o,[["render",p]]);export{$ as __pageData,k as default};
